{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da85d4d-99f8-429d-acf0-7363f77054e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"intents\": [\n",
    "        {\"tag\": \"greeting\",\n",
    "         \"patterns\": [\"Hi\", \"Hello\", \"How are you?\", \"Good day\", \"Hey\"],\n",
    "         \"responses\": [\"Hello!\", \"Hi there!\", \"Greetings!\", \"How can I assist you?\"]\n",
    "        },\n",
    "        {\"tag\": \"goodbye\",\n",
    "         \"patterns\": [\"Bye\", \"See you\", \"Goodbye\", \"Catch you later\"],\n",
    "         \"responses\": [\"Goodbye!\", \"See you soon!\", \"Have a nice day!\"]\n",
    "        },\n",
    "        {\"tag\": \"thanks\",\n",
    "         \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks a lot\"],\n",
    "         \"responses\": [\"You're welcome!\", \"Happy to help!\", \"Anytime!\"]\n",
    "        },\n",
    "        {\"tag\": \"hours\",\n",
    "         \"patterns\": [\"What are your hours?\", \"When are you open?\", \"Opening hours\"],\n",
    "         \"responses\": [\"We are open 9am to 5pm, Monday to Friday.\"]\n",
    "        },\n",
    "        {\"tag\": \"payments\",\n",
    "         \"patterns\": [\"Do you accept credit cards?\", \"What payment methods do you support?\"],\n",
    "         \"responses\": [\"We accept Visa, Mastercard and PayPal.\"]\n",
    "        },\n",
    "        {\"tag\": \"fallback\",\n",
    "         \"patterns\": [],\n",
    "         \"responses\": [\"Sorry, I didn't understand that. Can you rephrase?\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save dataset\n",
    "with open(\"intents.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df759a7-c1c1-44cb-a570-1f6f3075cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    # Remove punctuation and stopwords, lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Example usage\n",
    "print(preprocess_text(\"Hello! How are you doing today?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51bfa8-1863-45ef-95b3-63580257d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    # Remove punctuation and stopwords, lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Example usage\n",
    "print(preprocess_text(\"Hello! How are you doing today?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96571e13-a768-4c3a-98b4-f9afee8916ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load data\n",
    "with open('intents.json') as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Extract patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(pattern)\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Preprocess all patterns\n",
    "processed_patterns = [' '.join(preprocess_text(p)) for p in patterns]\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(processed_patterns)\n",
    "\n",
    "print(X.shape)  # (number of patterns, number of features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc5628-7a1b-43eb-afff-a5d17c195615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, tags, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d811d-62d9-457f-87d3-aeff909afe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def chatbot_response(text):\n",
    "    # Preprocess and vectorize input text\n",
    "    text_processed = ' '.join(preprocess_text(text))\n",
    "    text_vec = vectorizer.transform([text_processed])\n",
    "    \n",
    "    # Predict intent\n",
    "    pred_tag = clf.predict(text_vec)[0]\n",
    "    \n",
    "    # If confidence is low, fallback\n",
    "    prob = clf.predict_proba(text_vec).max()\n",
    "    if prob < 0.4:  # threshold for fallback\n",
    "        pred_tag = \"fallback\"\n",
    "    \n",
    "    # Get response\n",
    "    for intent in intents['intents']:\n",
    "        if intent['tag'] == pred_tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "# Try chatbot\n",
    "print(chatbot_response(\"Hey there!\"))\n",
    "print(chatbot_response(\"What time do you open?\"))\n",
    "print(chatbot_response(\"Can you do my homework?\"))  # Should fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d46b50-f681-41bc-a2d4-a5e8b5c84c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def chatbot_response(text):\n",
    "    # Preprocess and vectorize input text\n",
    "    text_processed = ' '.join(preprocess_text(text))\n",
    "    text_vec = vectorizer.transform([text_processed])\n",
    "    \n",
    "    # Predict intent\n",
    "    pred_tag = clf.predict(text_vec)[0]\n",
    "    \n",
    "    # If confidence is low, fallback\n",
    "    prob = clf.predict_proba(text_vec).max()\n",
    "    if prob < 0.4:  # threshold for fallback\n",
    "        pred_tag = \"fallback\"\n",
    "    \n",
    "    # Get response\n",
    "    for intent in intents['intents']:\n",
    "        if intent['tag'] == pred_tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "# Try chatbot\n",
    "print(chatbot_response(\"Hey there!\"))\n",
    "print(chatbot_response(\"What time do you open?\"))\n",
    "print(chatbot_response(\"Can you do my homework?\"))  # Should fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142073c4-db69-4f44-a2bc-c617cc378512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chatbot is running! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    response = chatbot_response(user_input)\n",
    "    print(f\"Chatbot: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb40b15-031d-4c27-a83b-8b959c4e4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Download the English model if not installed: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def spacy_preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "print(spacy_preprocess(\"Hello! How are you doing today?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea282d24-be4b-466a-9e07-9621d7c64fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Prepare training data (patterns and tags)\n",
    "with open('intents.json') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "patterns = []\n",
    "tags = []\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(pattern)\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Get embeddings for each pattern\n",
    "embeddings = model.encode(patterns)\n",
    "\n",
    "# Train a KNN classifier (works well with embeddings)\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "knn.fit(embeddings, tags)\n",
    "\n",
    "# Predict intent function\n",
    "def predict_intent_bert(text):\n",
    "    emb = model.encode([text])\n",
    "    distances, indices = knn.kneighbors(emb)\n",
    "    pred_tag = knn.predict(emb)[0]\n",
    "    confidence = 1 - distances[0][0]  # cosine similarity as confidence\n",
    "\n",
    "    # Fallback threshold\n",
    "    if confidence < 0.5:\n",
    "        pred_tag = \"fallback\"\n",
    "    \n",
    "    return pred_tag, confidence\n",
    "\n",
    "# Test it\n",
    "tag, conf = predict_intent_bert(\"Can you tell me your opening hours?\")\n",
    "print(f\"Predicted intent: {tag}, Confidence: {conf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0b359-08e5-416d-a6ea-2fb42524093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "print(extract_entities(\"I want to book a flight to New York next Monday\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4b0d7-757c-43b9-ba5b-e697a24d489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotContext:\n",
    "    def __init__(self):\n",
    "        self.context = {}\n",
    "    \n",
    "    def update(self, intent, entities):\n",
    "        self.context['last_intent'] = intent\n",
    "        self.context['last_entities'] = entities\n",
    "    \n",
    "    def get_context(self):\n",
    "        return self.context\n",
    "\n",
    "context = ChatbotContext()\n",
    "\n",
    "def chatbot_response_advanced(text):\n",
    "    intent, confidence = predict_intent_bert(text)\n",
    "    entities = extract_entities(text)\n",
    "    \n",
    "    # Update context\n",
    "    context.update(intent, entities)\n",
    "\n",
    "    # Choose response\n",
    "    for intent_data in intents['intents']:\n",
    "        if intent_data['tag'] == intent:\n",
    "            response = np.random.choice(intent_data['responses'])\n",
    "            break\n",
    "    else:\n",
    "        response = \"Sorry, I didn't get that.\"\n",
    "\n",
    "    # Add entities info to response for demonstration\n",
    "    if entities:\n",
    "        response += f\" (I noticed you mentioned: {entities})\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Try chat\n",
    "print(chatbot_response_advanced(\"Hi there!\"))\n",
    "print(chatbot_response_advanced(\"Can you tell me your working hours?\"))\n",
    "print(chatbot_response_advanced(\"I want to pay with a credit card.\"))\n",
    "print(chatbot_response_advanced(\"Book a flight to Paris next Friday.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f4c73-6877-4917-b4b6-676478cef212",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a0ee5-b68b-40fa-99dc-f3e560e8c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Advanced AI Chatbot\")\n",
    "\n",
    "context = ChatbotContext()\n",
    "\n",
    "user_input = st.text_input(\"You:\")\n",
    "\n",
    "if user_input:\n",
    "    response = chatbot_response_advanced(user_input)\n",
    "    st.text_area(\"Chatbot:\", value=response, height=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51e9e7-1632-43a3-b36b-0c0b3cf9a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646729a2-9a2e-4aa3-8b26-3ab49d3b77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810c178-6844-4396-9147-cadecfb057f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(knn, \"knn_intent_model.joblib\")\n",
    "joblib.dump(model, \"sentence_transformer_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263f64c-9939-41fb-b8db-65f255f19b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = joblib.load(\"knn_intent_model.joblib\")\n",
    "model = joblib.load(\"sentence_transformer_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515dbde8-5ca0-4eec-96c6-00183078b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def chatbot_response(text):\n",
    "    # Preprocess and vectorize input text\n",
    "    text_processed = ' '.join(preprocess_text(text))\n",
    "    text_vec = vectorizer.transform([text_processed])\n",
    "    \n",
    "    # Predict intent\n",
    "    pred_tag = clf.predict(text_vec)[0]\n",
    "    \n",
    "    # If confidence is low, fallback\n",
    "    prob = clf.predict_proba(text_vec).max()\n",
    "    if prob < 0.4:  # threshold for fallback\n",
    "        pred_tag = \"fallback\"\n",
    "    \n",
    "    # Get response\n",
    "    for intent in intents['intents']:\n",
    "        if intent['tag'] == pred_tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "# Try chatbot\n",
    "print(chatbot_response(\"Hey there!\"))\n",
    "print(chatbot_response(\"What time do you open?\"))\n",
    "print(chatbot_response(\"Can you do my homework?\"))  # Should fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394423f-7f94-448d-a4eb-2aad0d67cf63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda]",
   "language": "python",
   "name": "conda-env-Anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

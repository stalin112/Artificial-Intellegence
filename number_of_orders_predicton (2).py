# -*- coding: utf-8 -*-
"""Number of orders predicton.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fvx0oceRCOktEIIKQCdYz-1oi84GaEms
"""

import pandas as pd
import numpy as np

"""Now that the files are extracted, let's load one of the CSV files into a pandas DataFrame. Based on the extracted files, I'll load `olist_customers_dataset.csv` as an example. You can change the filename if you want to load a different dataset."""

zip_path = '/content/Brazilian E-Commerce Public Dataset by Olist.zip'
with open(zip_path, 'wb') as f:
    f.write(uploaded['archive (2).zip'])
extract_path = '/content/'
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)
extracted_files = os.listdir(extract_path)
print("Extracted files:", extracted_files)

# Convert timestamp columns to datetime objects
orders_df['order_purchase_timestamp'] = pd.to_datetime(orders_df['order_purchase_timestamp'])

# Get the minimum and maximum order purchase dates
min_date = orders_df['order_purchase_timestamp'].min()
max_date = orders_df['order_purchase_timestamp'].max()

print("Dataset Name: Brazilian E-Commerce Public Dataset by Olist")
print(f"The order records in this dataset span across the years {min_date.year} and {max_date.year}.")
print("This historical sales data is essential for understanding customer behavior and trends.")

import os
import pandas as pd
extract_path = '/content/'
print("Files in extraction path:", os.listdir(extract_path))
df = pd.read_csv(os.path.join(extract_path, 'olist_customers_dataset.csv'))
display(df.head())

df.info()

df.isnull().sum()

"""Let's start by exploring the basic information about the DataFrame."""

df.info()

"""Next, let's look at descriptive statistics for the numerical columns."""

display(df.describe())

"""Now, let's examine the unique values and their counts for the categorical columns, starting with `customer_state`."""

display(df['customer_state'].value_counts())

"""Let's do the same for the `customer_city` column."""

# Display the top 20 cities due to the large number of unique citie
display(df['customer_city'].value_counts().head(20))

import matplotlib.pyplot as plt
import seaborn as sns

# Get the count of customers per state
state_counts = df['customer_state'].value_counts()

# Create a bar plot
plt.figure(figsize=(12, 6))
sns.barplot(x=state_counts.index, y=state_counts.values, palette='viridis')
plt.title('Number of Customers per State')
plt.xlabel('State')
plt.ylabel('Number of Customers')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Let's load the orders dataset and merge it with the customer data."""

orders_df = pd.read_csv(os.path.join(extract_path, 'olist_orders_dataset.csv'))
display(orders_df.head())

"""Now, let's merge the customer and orders DataFrames. We can merge them on the `customer_id` column."""

# Merge the two DataFrames on 'customer_id'
merged_df = pd.merge(df, orders_df, on='customer_id', how='inner')
display(merged_df.head())

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
uploaded = files.upload()

import zipfile
import os

zip_path = '/content/Brazilian E-Commerce Public Dataset by Olist.zip'
with open(zip_path, 'wb') as f:
    f.write(uploaded['archive (2).zip'])
extract_path = '/content/'
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)
extracted_files = os.listdir(extract_path)
print("Extracted files:", extracted_files)



"""Let's load the order payments dataset and merge it with the existing DataFrame."""

# Load the order payments dataset
payments_df = pd.read_csv(os.path.join(extract_path, 'olist_order_payments_dataset.csv'))
display(payments_df.head())

"""Now, let's merge the `merged_df` (which contains customer and order info) with the `payments_df` on the `order_id` column."""

# Merge the merged_df and payments_df on 'order_id'
final_merged_df = pd.merge(merged_df, payments_df, on='order_id', how='inner')

# Display the first few rows of the final merged DataFrame
display(final_merged_df.head())

# Get unique values and their counts for the 'payment_type' column
display(final_merged_df['payment_type'].value_counts())

"""Let's load the order items dataset and merge it with the existing DataFrame."""

# Load the order items dataset
order_items_df = pd.read_csv(os.path.join(extract_path, 'olist_order_items_dataset.csv'))

# Display the first few rows of the order items DataFrame
display(order_items_df.head())

"""Now, let's merge the `final_merged_df` with the `order_items_df` on the `order_id` column."""

# Merge the final_merged_df and order_items_df on 'order_id'
full_merged_df = pd.merge(final_merged_df, order_items_df, on='order_id', how='inner')
display(full_merged_df.head())

plt.figure(figsize=(10, 6))
sns.histplot(full_merged_df['payment_value'], bins=50, kde=True)
plt.title('Distribution of Payment Values')
plt.xlabel('Payment Value')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(data=full_merged_df, x='payment_type', order=full_merged_df['payment_type'].value_counts().index, palette='viridis')
plt.title('Distribution of Payment Types')
plt.xlabel('Payment Type')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""# Task
Analyze customer preferences and what they regularly buy using the datasets: "olist_products_dataset.csv", "product_category_name_translation.csv", and the previously created `full_merged_df`.

## Load products and category translation data

### Subtask:
Load the `olist_products_dataset.csv` and `product_category_name_translation.csv` files into DataFrames.

**Reasoning**:
The subtask requires loading two CSV files into pandas DataFrames. I will use `pd.read_csv` to load the specified files and display the head of each DataFrame to confirm successful loading as requested in the instructions.
"""

# Load the products dataset
products_df = pd.read_csv(os.path.join(extract_path, 'olist_products_dataset.csv'))

# Load the product category name translation dataset
category_translation_df = pd.read_csv(os.path.join(extract_path, 'product_category_name_translation.csv'))

# Display the first few rows of both DataFrames
display(products_df.head())
display(category_translation_df.head())

"""## Merge products and category translation

### Subtask:
Merge the products and category translation DataFrames to get human-readable product category names.

**Reasoning**:
Merge the products and category translation dataframes on the 'product_category_name' column to get English category names.
"""

# Merge products_df with category_translation_df on 'product_category_name'
products_with_english_category = pd.merge(products_df, category_translation_df, on='product_category_name', how='inner')
# Display the first few rows of the merged DataFrame
display(products_with_english_category.head())

"""## Merge with full data

### Subtask:
Merge the combined product and category data with the `full_merged_df` (which contains customer, order, payment, and order items information).

**Reasoning**:
Merge the `full_merged_df` with the `products_with_english_category` DataFrame on 'product_id' using an inner merge and display the head of the resulting DataFrame to verify the merge.
"""

# Merge the full_merged_df and products_with_english_category on 'product_id'
complete_data_df = pd.merge(full_merged_df, products_with_english_category, on='product_id', how='inner')
# Display the first few rows of the new merged DataFrame
display(complete_data_df.head())

"""## Analyze customer purchase frequency by category

### Subtask:
Group the merged data by `customer_unique_id` and product category to find out which categories each customer buys most often.

**Reasoning**:
Group the data by customer and product category and count the occurrences to find out the most frequent categories for each customer.
"""

# Group by customer_unique_id and product_category_name_english and count occurrences
customer_category_counts = complete_data_df.groupby(['customer_unique_id', 'product_category_name_english']).size().reset_index(name='purchase_count')
# Sort by customer and purchase count in descending order
customer_category_counts = customer_category_counts.sort_values(by=['customer_unique_id', 'purchase_count'], ascending=[True, False])
display(customer_category_counts.head())

"""## Identify regular purchases

### Subtask:
Determine what customers "regularly buy" based on the frequency of purchases within categories or specific products.

**Reasoning**:
Group the complete data by customer and product to count individual product purchases, then group by customer and category to count category purchases. After that, filter both dataframes based on defined purchase thresholds to identify "regular" purchases at both product and category levels. Finally, display the first few rows of the filtered dataframes.
"""

# Group by customer_unique_id and product_id to count product purchases
customer_product_counts = complete_data_df.groupby(['customer_unique_id', 'product_id']).size().reset_index(name='product_purchase_count')
# Group by customer_unique_id and product_category_name_english to count category purchases
customer_category_counts = complete_data_df.groupby(['customer_unique_id', 'product_category_name_english']).size().reset_index(name='category_purchase_count')
regular_product_purchases = customer_product_counts[customer_product_counts['product_purchase_count'] >= 2]
regular_category_purchases = customer_category_counts[customer_category_counts['category_purchase_count'] >= 3]
print("Regular Product Purchases (2+ purchases of the same product):")
display(regular_product_purchases.head())
print("\nRegular Category Purchases (3+ purchases from the same category):")
display(regular_category_purchases.head())

"""## Summary:

### Data Analysis Key Findings

*   The analysis identified customers who have purchased the same product at least twice.
*   The analysis identified customers who have purchased from the same product category at least three times.

### Insights or Next Steps

*   These identified regular purchases can be used to understand customer loyalty at both the product and category levels, informing targeted marketing and product recommendations.
*   Further analysis could involve looking at the time elapsed between these regular purchases to understand the repurchase cycle.

## Load products and category translation data

### Subtask:
Load the `olist_products_dataset.csv` and `product_category_name_translation.csv` files into DataFrames.

**Reasoning**:
The subtask requires loading two CSV files into pandas DataFrames. I will use `pd.read_csv` to load the specified files and display the head of each DataFrame to confirm successful loading as requested in the instructions.
"""

# Load the products dataset
products_df = pd.read_csv(os.path.join(extract_path, 'olist_products_dataset.csv'))
# Load the product category name translation dataset
category_translation_df = pd.read_csv(os.path.join(extract_path, 'product_category_name_translation.csv'))
# Display the first few rows of both DataFrames
display(products_df.head())
display(category_translation_df.head())

"""## Merge products and category translation

### Subtask:
Merge the products and category translation DataFrames to get human-readable product category names.

**Reasoning**:
Merge the products and category translation dataframes on the 'product_category_name' column to get English category names.
"""

# Merge products_df with category_translation_df on 'product_category_name'
products_with_english_category = pd.merge(products_df, category_translation_df, on='product_category_name', how='inner')

# Display the first few rows of the merged DataFrame
display(products_with_english_category.head())

"""## Merge with full data

### Subtask:
Merge the combined product and category data with the `full_merged_df` (which contains customer, order, payment, and order items information).

**Reasoning**:
Merge the `full_merged_df` with the `products_with_english_category` DataFrame on 'product_id' using an inner merge and display the head of the resulting DataFrame to verify the merge.
"""

# Merge the full_merged_df and products_with_english_category on 'product_id'
complete_data_df = pd.merge(full_merged_df, products_with_english_category, on='product_id', how='inner')

# Display the first few rows of the new merged DataFrame
display(complete_data_df.head())

"""## Analyze customer purchase frequency by category

### Subtask:
Group the merged data by `customer_unique_id` and product category to find out which categories each customer buys most often.

**Reasoning**:
Group the data by customer and product category and count the occurrences to find out the most frequent categories for each customer.
"""

# Group by customer_unique_id and product_category_name_english and count occurrences
customer_category_counts = complete_data_df.groupby(['customer_unique_id', 'product_category_name_english']).size().reset_index(name='purchase_count')

# Sort by customer and purchase count in descending order
customer_category_counts = customer_category_counts.sort_values(by=['customer_unique_id', 'purchase_count'], ascending=[True, False])

# Display the first few rows
display(customer_category_counts.head())

"""## Identify regular purchases

### Subtask:
Determine what customers "regularly buy" based on the frequency of purchases within categories or specific products.

**Reasoning**:
Group the complete data by customer and product to count individual product purchases, then group by customer and category to count category purchases. After that, filter both dataframes based on defined purchase thresholds to identify "regular" purchases at both product and category levels. Finally, display the first few rows of the filtered dataframes.
"""

# Group by customer_unique_id and product_id to count product purchases
customer_product_counts = complete_data_df.groupby(['customer_unique_id', 'product_id']).size().reset_index(name='product_purchase_count')

# Group by customer_unique_id and product_category_name_english to count category purchases
customer_category_counts = complete_data_df.groupby(['customer_unique_id', 'product_category_name_english']).size().reset_index(name='category_purchase_count')

# Filter for product-level regular purchases (e.g., 2 or more purchases of the same product)
regular_product_purchases = customer_product_counts[customer_product_counts['product_purchase_count'] >= 2]

# Filter for category-level regular purchases (e.g., 3 or more purchases from the same category)
regular_category_purchases = customer_category_counts[customer_category_counts['category_purchase_count'] >= 3]

# Display the first few rows of the filtered DataFrames
print("Regular Product Purchases (2+ purchases of the same product):")
display(regular_product_purchases.head())

print("\nRegular Category Purchases (3+ purchases from the same category):")
display(regular_category_purchases.head())